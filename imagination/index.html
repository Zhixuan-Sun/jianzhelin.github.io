<html>
<head>
<title>Acquiring Visual Classifiers from Human Imagination - MIT</title>
<meta name="google-site-verification" content="NksNPfO4SApMtvU2rGHxr4DPan2Uy6Pz-rP9cA0k1mg" />
<script type="text/javascript" src="jquery.js"></script>
<!--<script type="text/javascript" src="firefly/jquery-firefly-0.2.js"></script>-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-17813713-3', 'mit.edu');
  ga('send', 'pageview');

</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<style>
body
{
    font-family : Arial;
    background-color : #f7f6f8;
}
.content
{
    width : 800px;
    padding : 25px 25px;
    margin : 35px auto;
	background-color : #fff;
    border-radius: 15px; 
}

.acknowledgements
{
    width : 800px;
    padding : 0px 50px;
    margin : 35px auto;
}

.title {
    background-color : inherit;
    box-shadow : none;
    border-radius : 0;
    margin : 0 auto;
    padding : 25px 0 0 0;
    width : 800px;
}

blockquote
{
    line-height : 22px;
    font-style : italic;
}

.text {

/*-webkit-column-count:2;
-moz-column-count:2; 
column-count:2;
column-gap:40px;
-moz-column-gap:40px; 
-webkit-column-gap:40px;*/
width : 600px;
text-align : justify;
margin : 0 auto;

}

.contentblock
{
    width : 950px;
    margin : 0 auto;
    padding : 0;
    border-spacing : 25px 0;
}

.contentblock td
{
    background-color : #fff;
    padding : 25px 50px;
    vertical-align : top;
    box-shadow: 0px 0px 10px #999;
    border-radius: 15px; 
}

a, a:visited
{
    color : blue;
}

#authors
{
    text-align : center;
    margin-bottom : 20px;
}

#conference
{
    text-align : center;
    margin-bottom : 20px;
    font-style : italic;
}

#authors a 
{
    margin : 0 10px;
}

h1
{
    text-align : center;
    font-family : Arial;
    font-size : 28px;
}

h2
{
    font-family : Arial;
    font-size : 24px;
}

code
{
	display : block;
	padding : 10px;
	margin : 10px 10px;
}


p 
{
    line-height : 22px;
    margin : 0;
    padding : 0;
    margin : 10px 0;
}

p.caption {
    text-indent : 0;
    font-size : 14px;
}

p code
{
    display : inline;
    padding : 0;
    margin : 0;
}

li {
    margin : 10px 0;
}

.acknowledgements p
{
    text-indent : 0;
    font-size : 14px;
}

#download
{
    padding-top : 20px;
    padding-bottom : 20px;
    text-align : center;
}

#download a 
{
    text-decoration : none;
    text-align : center;
    color : #fff;
    background-color : #566dfa;
    padding : 20px 30px;
    border-radius: 20px;
    font-weight : bold;
}
#download a:hover {
    background-color : #161af2; 
}

img.rounded
{
    border-radius: 10px;
    border : #ccc 1px solid;
}

#ci-noise
{
    display : block;
    width : 155px;
    height : 153px;
    background-image : url('noise.png');
    margin-top : 35px;
}

#ci-table {
    margin : 0 auto 0px auto;
    width : 800px;
}   

#ci-head {
    display : block;
    width : 383;
    height : 210px;
    background-image : url('head-all.png');
    background-position : 0px 0px;
    margin-left : 40px;
    margin-right : 40px;
}

#ci-car {
    display : block;
    width : 155px;
    height : 155px;
    background-image : url('car-ci.png');
    margin-top : 35px;
}

#ci-labels td {
    text-align : center;
    padding-top : 10px;
    font-size : 12px;
}

#sportsball {
    margin : 0 auto; 
}

#sportsball td {
    padding : 5px 20px;
    text-align : center;
}

.figure {
    text-align : center;
    margin : 20px auto;
}

</style>
<script>

$(document).ready(function() {
    var noiseid = 0;
    window.setInterval(function() {
        var singleoffset = 458-209;
        var offset = Math.random() > 0.5 ? singleoffset : (singleoffset*2);

        noiseid = (noiseid + 1) % 9;

        $("#ci-head").css('background-position', "0px " + (-offset) + "px");
        $("#ci-noise").show().css("background-position", (-noiseid * 189) + "px 0px");

        window.setTimeout(function() {
            $("#ci-head").css('background-position', '0px 0px');
        }, 300);
    }, 500);
});

</script>
</head>

<body>

<div class="title">
<h1>Acquiring Visual Classifiers from Human Imagination</h1>
<p id="authors">
<a href="http://mit.edu/vondrick">Carl Vondrick</a>
<a href="http://people.csail.mit.edu/hpirsiav/">Hamed Pirsiavash</a>
<a href="http://cvcl.mit.edu/audeoliva.html">Aude Oliva</a>
<a href="http://web.mit.edu/torralba/www/">Antonio Torralba</a><br>
Massachusetts Institute of Technology
</p>

<p id="download"><a href="paper.pdf">Download the full paper</a></p>

</div>

<div class="content" id="ci">

<div class="text">

<h2>Abstract</h2>

<p>The human mind can remarkably imagine objects that it has never seen,
touched,  or heard, all in vivid detail. Motivated by the desire to harness
this rich source of information from the human mind, this paper investigates
how to extract classifiers from the human visual system and leverage them in a
machine. We introduce a method that, inspired by well-known tools in human
psychophysics, estimates the classifier that the human visual system might use
for recognition, but in computer vision feature spaces.   Our experiments are
surprising, and suggest that classifiers from the human visual system can be
transferred into a machine with some success. Since these classifiers seem to
capture favorable biases in the human visual system, we present a novel SVM
formulation that constrains the orientation of the SVM hyperplane to agree with
the human visual system. Our results suggest that transferring this human bias
into machines can help object recognition systems generalize across datasets.
Moreover, we found that people's culture may subtly vary the objects that
people imagine, which influences this bias.  Overall, human imagination can be
an interesting resource for future visual recognition systems.  </p>

<p>To learn more, <a href="paper.pdf">download our paper</a> and scroll down 
for some results.</p>

</div>
</div>

<div class="content">
<div class="text">
<h2>Acquiring Classifiers</h2>

<p>Human psychophysics researchers have developed procedures to estimate and
interpret the classifiers that the human visual system uses for recognition. We
are building off these tools to extract classifiers from the human visual
system, and transfer it into a machine.</p>

<p>We describe our method in detail in <a href="paper.pdf">our paper</a>. On a
high level, our approach works by showing humans white noise in feature space and
asking them to indicate whether they perceive an object in the noise. By
applying basic statistics to their responses, we can estimate the decision
boundary that the human visual system is using for discrimination. Since we use
white noise, and not real images, we avoid priming the subjects, and instead capture
subtle details from people's imagination.</p>

</div>

<div id="ci-table">
<table>
<tr>
<td><div id="ci-noise"></div></td>
<td><div id="ci-head"></div></td>
<td><div id="ci-car"></div></td>
</tr>
<tr id="ci-labels">
<td>Noise in Feature Space</td>
<td>Human Visual System</td>
<td>Classifier for Car</td>
</tr>
</table>
</div>

</div>

<div class="content" id="results">
<div class="text">
<h2>Crowdsourced Imagination</h2>
<p>We extracted some classifiers that the human visual system of workers on Amazon Mechanical Turk might use to recognize objects. We visualize some of their imaginary classifiers below:</p>

</div>
<div class="figure">
<a href="all-ci.png"><img src="all-ci.png" style="width:700px"></a>
</div>
<div class="text">
<p style="text-indent:0;">Although the visualizations are blurry, structure emerges in many cases. In the car classifier, we can see a
vehicle-like object in the center sitting on top of a dark road and light sky.
The television shows a rectangular structure, and the fire hydrant
reveals a red hydrant with two arms on the side.</p>
</div>
</div>

<div class="content">
<div class="text">
<h2>Recognition</h2>

<p>Our paper tries to scientifically understand how well we can acquire
classifiers from the human visual system and leverage them computationally. To quantify this, we
evaluated the imaginary classifiers on their ability to recognize objects. We show
some of the images that the imaginary classifiers scored highly:</p>
</div>

<div class="figure">
<a href="topclass.png"><img src="topclass.png" style="width:680px;"></a>
</div>

<div class="text">
<p style="text-indent:0;">The full quantitative results in <a href="paper.pdf">our paper</a> suggest that the imaginary classifiers are capturing
some signal from the human visual system. In nearly every case, these classifiers do contain some discriminative power.</p>
</div>

</div>

<div class="content">
<div class="text">
<h2>Transferring into Machines</h2>
<p>Since the imaginary classifiers are estimated from the human visual system,
we expect it to capture good biases about the visual world. We are able to
transfer this human bias into SVMs by constraining the hyperplane \(w \in \mathbb{R}^d\)
to be oriented at most \(\cos^{-1}(\theta)\) degrees away from the imaginary classifier \(c \in \mathbb{R}^d\):
$$
\begin{aligned}
\min_{w,b,\xi} \enspace &||w||_2^2 + \lambda\sum_{i=1}^n \xi_i \\
\mathrm{s.t.} \enspace &y_i \left(w^T x_i + b\right) \ge 1 - \xi_i, \quad \xi_i \ge 0, \\
&\theta \le \frac{w^T c}{||w||_2||c||_2}
\end{aligned}
$$
The above is a standard linear SVM, except the last constraint forces the solution to be oriented similar to the classifier acquired from the human visual system.</p>

<p>The experiments in <a href="paper.pdf">our paper</a> suggest that transferring the bias in the imaginary classifiers into machine learning may benefit object recognition on generalizing across datasets.</p>
</div>
</div>


<div class="content">
<div class="text">
<h2>Mental Images</h2>

<p>Our culture and experiences can subtly influence the objects that we imagine. We created classifiers for sports balls for people in different geographic locations:</p>

<table id="sportsball">
<tr>
<td><img src="mental-printing-india.jpg" style="width:150px;"></td>
<td><img src="mental-printing-us.jpg" style="width:150px;"></td>
</tr>
<tr>
<td>India</td>
<td>United States</td>
</tr>
</table>

<p>Even though both sets of workers
were labeling noise from the same distribution, Indian workers seemed to imagine red balls, while
American workers tended to imagine orange/brown balls. Remarkably, the most
popular sport in India is cricket, which is played with a red ball, and popular
sports in the United States are American football and basketball, which are
played with brown/orange balls. We hypothesize that Americans and Indians may have different mental images
of
sports balls, biased by their culture.</p>

</div>
</div>


<div class="content">
<div class="text">
<h2>Learn More</h2>

<p>We encourage readers to see <a href="paper.pdf">our paper</a> to learn more. Our results may surprise you!</p>

</div>
</div>


</body>
</html>
